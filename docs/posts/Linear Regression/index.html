<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Anweshan Adhikari">
<meta name="description" content="Understanding different approaches to implement the Linear Regression Model">

<title>Anweshan’s Blog - Implementing Linear Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap" rel="stylesheet">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Anweshan’s Blog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">About me</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#implementation" id="toc-implementation" class="nav-link" data-scroll-target="#implementation">Implementation</a></li>
  <li><a href="#gradient-descent-accuracy-score-over-iterations" id="toc-gradient-descent-accuracy-score-over-iterations" class="nav-link" data-scroll-target="#gradient-descent-accuracy-score-over-iterations">Gradient Descent: Accuracy Score over Iterations</a></li>
  <li><a href="#implementing-lasso" id="toc-implementing-lasso" class="nav-link" data-scroll-target="#implementing-lasso">Implementing LASSO</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Implementing Linear Regression</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li></ul></div></div>
</div>

<div>
  <div class="description">
    Understanding different approaches to implement the Linear Regression Model
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Anweshan Adhikari </p>
          </div>
  </div>
    
    
  </div>
  

</header>

<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In this blog post, we will be implementing the least square linear regression model in two ways: Analytical Method and Gradient Descent Method. Before diving deeper, let’s understand what a least square linear regression model is.</p>
<p>A linear regression model simply tries to find a relationship between the features and the target variable. The model does so by minimizing the overall squared deviations between the predicted values and actual values to find the best relationship. The two approaches that we will be implementing are the Analytical Method and Gradient Descent Method. Let’s understand how each of these methods work:</p>
<p><code>Analytical Method:</code> When we set the gradient of the loss function to zero, which is the condition for minimizing the loss function, we derive an explicit formula for <span class="math inline">\(\widehat{w}\)</span> i.e <span class="math inline">\(\widehat{w} = (X^T X)^{-1} X^T y\)</span>. This is a direct method where we don’t need to guess parameters iteratively, unlike in gradient descent. However, this method can be computationally expensive and inefficient for large datasets due to the need to compute the inverse of a matrix, which has a computational complexity of O(n^3)</p>
<p><code>Gradient Descent Method:</code> The gradient descent does not try to solve the optimization problem in one go, but it uses an iterative approach to slowly converge towards the minimum of the function. In this method we first start with a random initialization of our parameter vector <span class="math inline">\(\widehat{w}\)</span> and repeteadly adjust the vector. We saw in the lecturenotes that the gradient of the loss function can be computed by <span class="math inline">\(\widehat{w} = (2X^T)(Xw-y)\)</span>. On each iteration we can update the weight vector by using the general weight update function <span class="math inline">\(\widehat{w} = \widehat{w} - \alpha * gradient\)</span> and check for convergence. Choosing the learning rate <span class="math inline">\(\alpha\)</span> can be difficult and depending on the value the method can take a very long time to converge or overshoot the minimum and fail to converge.</p>
<p>Here’s a link to the code that demonstrates both these methods: <a href="https://github.com/An65011065/An65011065.github.io/blob/main/posts/Linear%20Regression/Linear_Regression.py">Linear Regression</a></p>
</section>
<section id="implementation" class="level1">
<h1>Implementation</h1>
<p>Let’s utilize our the analytic_fit method to first test the analytical method. However, we need to first create a set of training data and validation data.</p>
<div class="cell" data-execution_count="76">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt </span>
<span id="cb1-3"><a href="#cb1-3"></a></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="kw">def</span> pad(X):</span>
<span id="cb1-5"><a href="#cb1-5"></a>    <span class="cf">return</span> np.append(X, np.ones((X.shape[<span class="dv">0</span>], <span class="dv">1</span>)), <span class="dv">1</span>)</span>
<span id="cb1-6"><a href="#cb1-6"></a></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="kw">def</span> LR_data(n_train <span class="op">=</span> <span class="dv">100</span>, n_val <span class="op">=</span> <span class="dv">100</span>, p_features <span class="op">=</span> <span class="dv">1</span>, noise <span class="op">=</span> <span class="fl">.1</span>, w <span class="op">=</span> <span class="va">None</span>):</span>
<span id="cb1-8"><a href="#cb1-8"></a>    <span class="cf">if</span> w <span class="kw">is</span> <span class="va">None</span>: </span>
<span id="cb1-9"><a href="#cb1-9"></a>        w <span class="op">=</span> np.random.rand(p_features <span class="op">+</span> <span class="dv">1</span>) <span class="op">+</span> <span class="fl">.2</span></span>
<span id="cb1-10"><a href="#cb1-10"></a>    </span>
<span id="cb1-11"><a href="#cb1-11"></a>    <span class="co">#creating a random X_train matrix with n_train rows - data points - and p_features columns - the features</span></span>
<span id="cb1-12"><a href="#cb1-12"></a>    X_train <span class="op">=</span> np.random.rand(n_train, p_features)</span>
<span id="cb1-13"><a href="#cb1-13"></a>    y_train <span class="op">=</span> pad(X_train)<span class="op">@</span>w <span class="op">+</span> noise<span class="op">*</span>np.random.randn(n_train)</span>
<span id="cb1-14"><a href="#cb1-14"></a></span>
<span id="cb1-15"><a href="#cb1-15"></a>    X_val <span class="op">=</span> np.random.rand(n_val, p_features)</span>
<span id="cb1-16"><a href="#cb1-16"></a>    y_val <span class="op">=</span> pad(X_val)<span class="op">@</span>w <span class="op">+</span> noise<span class="op">*</span>np.random.randn(n_val)</span>
<span id="cb1-17"><a href="#cb1-17"></a>    </span>
<span id="cb1-18"><a href="#cb1-18"></a>    <span class="cf">return</span> X_train, y_train, X_val, y_val</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>To make visualization simpler, we are setting the number of features to 1:</p>
<div class="cell" data-execution_count="77">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>X_train, y_train, X_val, y_val <span class="op">=</span> LR_data(n_train <span class="op">=</span> <span class="dv">100</span>, n_val <span class="op">=</span> <span class="dv">100</span>, p_features <span class="op">=</span> <span class="dv">1</span>, noise <span class="op">=</span> <span class="fl">0.1</span>)</span>
<span id="cb2-2"><a href="#cb2-2"></a></span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="co">#creating a padded version of X_train and y_train</span></span>
<span id="cb2-4"><a href="#cb2-4"></a>X_train_padded <span class="op">=</span> pad(X_train)</span>
<span id="cb2-5"><a href="#cb2-5"></a>X_val_padded <span class="op">=</span> pad(X_val)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Here, we are visualizing the data:</p>
<div class="cell" data-execution_count="78">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>fig, axarr <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, sharex <span class="op">=</span> <span class="va">True</span>, sharey <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb3-2"><a href="#cb3-2"></a>plt.rcParams[<span class="st">"figure.figsize"</span>] <span class="op">=</span> (<span class="dv">15</span>,<span class="dv">5</span>)</span>
<span id="cb3-3"><a href="#cb3-3"></a>axarr[<span class="dv">0</span>].scatter(X_train, y_train, color<span class="op">=</span><span class="st">"purple"</span>)</span>
<span id="cb3-4"><a href="#cb3-4"></a>axarr[<span class="dv">1</span>].scatter(X_val, y_val, color<span class="op">=</span><span class="st">"purple"</span>)</span>
<span id="cb3-5"><a href="#cb3-5"></a>labs <span class="op">=</span> axarr[<span class="dv">0</span>].<span class="bu">set</span>(title <span class="op">=</span> <span class="st">"Training"</span>, xlabel <span class="op">=</span> <span class="st">"x"</span>, ylabel <span class="op">=</span> <span class="st">"y"</span>)</span>
<span id="cb3-6"><a href="#cb3-6"></a>labs <span class="op">=</span> axarr[<span class="dv">1</span>].<span class="bu">set</span>(title <span class="op">=</span> <span class="st">"Validation"</span>, xlabel <span class="op">=</span> <span class="st">"x"</span>, ylabel <span class="op">=</span> <span class="st">"y"</span>)</span>
<span id="cb3-7"><a href="#cb3-7"></a>plt.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-4-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We will use our Linear_Regression method in the Linear_Regression Class, to see how our implementation performs on the training and testing data. Printed below is the weight vector, accuracy score on the training data and the validation data.</p>
<div class="cell" data-execution_count="79">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="im">from</span> Linear_Regression <span class="im">import</span> Linear_Regression</span>
<span id="cb4-2"><a href="#cb4-2"></a></span>
<span id="cb4-3"><a href="#cb4-3"></a>lr <span class="op">=</span> Linear_Regression()</span>
<span id="cb4-4"><a href="#cb4-4"></a></span>
<span id="cb4-5"><a href="#cb4-5"></a><span class="co"># use the methods of the class</span></span>
<span id="cb4-6"><a href="#cb4-6"></a>lr.analytic_fit(X_train, y_train)</span>
<span id="cb4-7"><a href="#cb4-7"></a></span>
<span id="cb4-8"><a href="#cb4-8"></a><span class="bu">print</span>(<span class="ss">f"Weight vector: </span><span class="sc">{</span>lr<span class="sc">.</span>coefficients<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-9"><a href="#cb4-9"></a><span class="bu">print</span>(<span class="ss">f"Training score: </span><span class="sc">{</span>lr<span class="sc">.</span>accuracy_score(X_train, y_train)<span class="sc">.</span><span class="bu">round</span>(<span class="dv">4</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-10"><a href="#cb4-10"></a><span class="bu">print</span>(<span class="ss">f"Validation score: </span><span class="sc">{</span>lr<span class="sc">.</span>accuracy_score(X_val, y_val)<span class="sc">.</span><span class="bu">round</span>(<span class="dv">4</span>)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Weight vector: [1.14598322 0.98235482]
Training score: 0.881
Validation score: 0.8784</code></pre>
</div>
</div>
<p>The Linear Regression implementation using analytic method seems to do well with both our training and testing data. Let’s see, if that is the case with the gradient descent method:</p>
<div class="cell" data-execution_count="80">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="im">from</span> Linear_Regression <span class="im">import</span> Linear_Regression</span>
<span id="cb6-2"><a href="#cb6-2"></a></span>
<span id="cb6-3"><a href="#cb6-3"></a>lr2 <span class="op">=</span> Linear_Regression()</span>
<span id="cb6-4"><a href="#cb6-4"></a></span>
<span id="cb6-5"><a href="#cb6-5"></a>lr2.gradient_fit(X_train, y_train)</span>
<span id="cb6-6"><a href="#cb6-6"></a></span>
<span id="cb6-7"><a href="#cb6-7"></a><span class="bu">print</span>(<span class="ss">f"Weight vector: </span><span class="sc">{</span>lr2<span class="sc">.</span>coefficients<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-8"><a href="#cb6-8"></a><span class="bu">print</span>(<span class="ss">f"Training score: </span><span class="sc">{</span>lr2<span class="sc">.</span>accuracy_score(X_train, y_train)<span class="sc">.</span><span class="bu">round</span>(<span class="dv">4</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-9"><a href="#cb6-9"></a><span class="bu">print</span>(<span class="ss">f"Validation score: </span><span class="sc">{</span>lr2<span class="sc">.</span>accuracy_score(X_val, y_val)<span class="sc">.</span><span class="bu">round</span>(<span class="dv">4</span>)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Weight vector: [1.14628734 0.98183735]
Training score: 0.881
Validation score: 0.8784</code></pre>
</div>
</div>
<p>Both the methods result in the same weight vector and a similar accuracy scores on both the training and validation data. This shows that our implementation is correct because we are solving the same optimization problem.</p>
</section>
<section id="gradient-descent-accuracy-score-over-iterations" class="level1">
<h1>Gradient Descent: Accuracy Score over Iterations</h1>
<div class="cell" data-execution_count="81">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a>plt.plot(lr2.score_history)</span>
<span id="cb8-2"><a href="#cb8-2"></a>labels <span class="op">=</span> plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"Iteration"</span>, ylabel <span class="op">=</span> <span class="st">"Score"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>In our case, we are using the entire dataset in each iteration to calculate the gradient of the cost function, ensuring a consistent improvement in accuracy over iterations (We can see this in the graph above)- as opposed to Stochastic Gradient Descent which utilizes only a single or a few random data points per iteration.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="co"># Experiment: Number of Features and Accuracy Scores</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="104">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb10-2"><a href="#cb10-2"></a></span>
<span id="cb10-3"><a href="#cb10-3"></a>n_train <span class="op">=</span> <span class="dv">100</span>  </span>
<span id="cb10-4"><a href="#cb10-4"></a></span>
<span id="cb10-5"><a href="#cb10-5"></a>lr3 <span class="op">=</span> Linear_Regression()</span>
<span id="cb10-6"><a href="#cb10-6"></a>train_scores <span class="op">=</span> []</span>
<span id="cb10-7"><a href="#cb10-7"></a>val_scores <span class="op">=</span> []</span>
<span id="cb10-8"><a href="#cb10-8"></a></span>
<span id="cb10-9"><a href="#cb10-9"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_train):</span>
<span id="cb10-10"><a href="#cb10-10"></a>    X_train, y_train, X_val, y_val <span class="op">=</span> LR_data(n_train <span class="op">=</span> <span class="dv">100</span>, n_val <span class="op">=</span> <span class="dv">100</span>, p_features <span class="op">=</span> i, noise <span class="op">=</span> <span class="fl">0.1</span>)</span>
<span id="cb10-11"><a href="#cb10-11"></a>    lr3.gradient_fit(X_train, y_train)</span>
<span id="cb10-12"><a href="#cb10-12"></a>    train_scores.append(lr3.accuracy_score(X_train, y_train))</span>
<span id="cb10-13"><a href="#cb10-13"></a>    val_scores.append(lr3.accuracy_score(X_val, y_val))</span>
<span id="cb10-14"><a href="#cb10-14"></a></span>
<span id="cb10-15"><a href="#cb10-15"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb10-16"><a href="#cb10-16"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, n_train), train_scores, label<span class="op">=</span><span class="st">'Training score'</span>)</span>
<span id="cb10-17"><a href="#cb10-17"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, n_train), val_scores, label<span class="op">=</span><span class="st">'Validation score'</span>)</span>
<span id="cb10-18"><a href="#cb10-18"></a>plt.title(<span class="st">'Training and Validation score vs. Number of features (Gradient Descent Approach)'</span>)</span>
<span id="cb10-19"><a href="#cb10-19"></a>plt.xlabel(<span class="st">'Number of features'</span>)</span>
<span id="cb10-20"><a href="#cb10-20"></a>plt.ylabel(<span class="st">'Score'</span>)</span>
<span id="cb10-21"><a href="#cb10-21"></a>plt.legend()</span>
<span id="cb10-22"><a href="#cb10-22"></a>plt.grid()</span>
<span id="cb10-23"><a href="#cb10-23"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>In our original implementation, our model had only one feature. To explore how the number of features influences model performance, we generated datasets with up to 100 features. For each dataset, we increased the number of features by one and calculated the accuracy score on both the training and validation sets.</p>
<p>The model’s performance on the training set improved with the addition of each new feature, reaching a near-perfect training score. This is because more features provide the model with more information, allowing it to fit the training databetter. However, in the validation score increased along with the training score, suggesting that the additional features were relating meaningful patterns but after the number of features exceeded 50, the validation score experienced a sharp decline.</p>
<p>This is an example of overfitting. Overfitting occurs when a model learns the training data too closely, including its noise and then fails to adapt appropriately to new data. Overfitting can also be observed in the analaytic approach of linear regression</p>
<div class="cell" data-execution_count="99">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb11-2"><a href="#cb11-2"></a></span>
<span id="cb11-3"><a href="#cb11-3"></a>n_train <span class="op">=</span> <span class="dv">100</span>  </span>
<span id="cb11-4"><a href="#cb11-4"></a></span>
<span id="cb11-5"><a href="#cb11-5"></a>lr3 <span class="op">=</span> Linear_Regression()</span>
<span id="cb11-6"><a href="#cb11-6"></a>train_scores <span class="op">=</span> []</span>
<span id="cb11-7"><a href="#cb11-7"></a>val_scores <span class="op">=</span> []</span>
<span id="cb11-8"><a href="#cb11-8"></a></span>
<span id="cb11-9"><a href="#cb11-9"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_train):</span>
<span id="cb11-10"><a href="#cb11-10"></a>    X_train, y_train, X_val, y_val <span class="op">=</span> LR_data(n_train <span class="op">=</span> <span class="dv">100</span>, n_val <span class="op">=</span> <span class="dv">100</span>, p_features <span class="op">=</span> i, noise <span class="op">=</span> <span class="fl">0.1</span>)</span>
<span id="cb11-11"><a href="#cb11-11"></a>    lr3.analytic_fit(X_train, y_train)</span>
<span id="cb11-12"><a href="#cb11-12"></a>    train_scores.append(lr3.accuracy_score(X_train, y_train))</span>
<span id="cb11-13"><a href="#cb11-13"></a>    val_scores.append(lr3.accuracy_score(X_val, y_val))</span>
<span id="cb11-14"><a href="#cb11-14"></a></span>
<span id="cb11-15"><a href="#cb11-15"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb11-16"><a href="#cb11-16"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, n_train), train_scores, label<span class="op">=</span><span class="st">'Training score'</span>)</span>
<span id="cb11-17"><a href="#cb11-17"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, n_train), val_scores, label<span class="op">=</span><span class="st">'Validation score'</span>)</span>
<span id="cb11-18"><a href="#cb11-18"></a>plt.title(<span class="st">'Training and Validation score vs. Number of features ( analytic approach)'</span>)</span>
<span id="cb11-19"><a href="#cb11-19"></a>plt.xlabel(<span class="st">'Number of features'</span>)</span>
<span id="cb11-20"><a href="#cb11-20"></a>plt.ylabel(<span class="st">'Score'</span>)</span>
<span id="cb11-21"><a href="#cb11-21"></a>plt.legend()</span>
<span id="cb11-22"><a href="#cb11-22"></a>plt.grid()</span>
<span id="cb11-23"><a href="#cb11-23"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-10-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="implementing-lasso" class="level1">
<h1>Implementing LASSO</h1>
<p>LASSO is a type of Linear Regression but it implements regularization too. The inclusion of a regularization term in LASSO makes it more robust to overfitting. Let’s see how LASSO deals with overfitting:</p>
<div class="cell" data-execution_count="103">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-2"><a href="#cb12-2"></a><span class="im">import</span> warnings</span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Lasso</span>
<span id="cb12-4"><a href="#cb12-4"></a></span>
<span id="cb12-5"><a href="#cb12-5"></a><span class="co"># Ignore warnings</span></span>
<span id="cb12-6"><a href="#cb12-6"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb12-7"><a href="#cb12-7"></a></span>
<span id="cb12-8"><a href="#cb12-8"></a>alpha_values <span class="op">=</span> [<span class="dv">0</span>, <span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>]</span>
<span id="cb12-9"><a href="#cb12-9"></a></span>
<span id="cb12-10"><a href="#cb12-10"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))  </span>
<span id="cb12-11"><a href="#cb12-11"></a>axs <span class="op">=</span> axs.flatten() </span>
<span id="cb12-12"><a href="#cb12-12"></a></span>
<span id="cb12-13"><a href="#cb12-13"></a><span class="cf">for</span> j, alpha <span class="kw">in</span> <span class="bu">enumerate</span>(alpha_values):</span>
<span id="cb12-14"><a href="#cb12-14"></a>    train_scores <span class="op">=</span> []</span>
<span id="cb12-15"><a href="#cb12-15"></a>    val_scores <span class="op">=</span> []</span>
<span id="cb12-16"><a href="#cb12-16"></a></span>
<span id="cb12-17"><a href="#cb12-17"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">100</span>):</span>
<span id="cb12-18"><a href="#cb12-18"></a>        X_train, y_train, X_val, y_val <span class="op">=</span> LR_data(n_train<span class="op">=</span><span class="dv">100</span>, n_val<span class="op">=</span><span class="dv">100</span>, p_features<span class="op">=</span>i, noise<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb12-19"><a href="#cb12-19"></a>        </span>
<span id="cb12-20"><a href="#cb12-20"></a>        L <span class="op">=</span> Lasso(alpha<span class="op">=</span>alpha)</span>
<span id="cb12-21"><a href="#cb12-21"></a>        L.fit(X_train, y_train)</span>
<span id="cb12-22"><a href="#cb12-22"></a></span>
<span id="cb12-23"><a href="#cb12-23"></a>        train_score <span class="op">=</span> L.score(X_train, y_train)</span>
<span id="cb12-24"><a href="#cb12-24"></a>        val_score <span class="op">=</span> L.score(X_val, y_val)</span>
<span id="cb12-25"><a href="#cb12-25"></a>        </span>
<span id="cb12-26"><a href="#cb12-26"></a>        train_scores.append(train_score)</span>
<span id="cb12-27"><a href="#cb12-27"></a>        val_scores.append(val_score)</span>
<span id="cb12-28"><a href="#cb12-28"></a></span>
<span id="cb12-29"><a href="#cb12-29"></a>    axs[j].plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">100</span>), train_scores, label<span class="op">=</span><span class="ss">f'Training score'</span>)</span>
<span id="cb12-30"><a href="#cb12-30"></a>    axs[j].plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">100</span>), val_scores, label<span class="op">=</span><span class="ss">f'Validation score'</span>)</span>
<span id="cb12-31"><a href="#cb12-31"></a>    axs[j].set_title(<span class="ss">f'Alpha = </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb12-32"><a href="#cb12-32"></a>    axs[j].set_xlabel(<span class="st">'Number of features'</span>)</span>
<span id="cb12-33"><a href="#cb12-33"></a>    axs[j].set_ylabel(<span class="st">'Score'</span>)</span>
<span id="cb12-34"><a href="#cb12-34"></a>    axs[j].legend()</span>
<span id="cb12-35"><a href="#cb12-35"></a>    axs[j].grid()</span>
<span id="cb12-36"><a href="#cb12-36"></a></span>
<span id="cb12-37"><a href="#cb12-37"></a>plt.tight_layout()</span>
<span id="cb12-38"><a href="#cb12-38"></a>plt.show()</span>
<span id="cb12-39"><a href="#cb12-39"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>When alpha is 0, it indicates no regularization. Hence the outcome should be no different than the standard linear regression model. As the alpha- the variable that controls regularization- increases, the performance on the performance on validation data is more consistent. This indicates that regularization in linear regression models is significant in combating overfitting.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">© 2023 Anweshan Adhikari</div>   
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



</body></html>